



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="Hexo" href="http://example.com/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="Hexo" href="http://example.com/atom.xml" />
<link rel="alternate" type="application/json" title="Hexo" href="http://example.com/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="运维" />


<link rel="canonical" href="http://example.com/2024/07/01/GPU%E5%85%A5%E9%97%A8%E6%A6%82%E8%AE%BA/">



  <title>
GPU入门概论 - 运维 |
Yume Shoka = Hexo</title>
<meta name="generator" content="Hexo 5.4.2"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">GPU入门概论
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2024-07-01 13:38:45">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2024-07-01T13:38:45+08:00">2024-07-01</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">Yume Shoka</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
        <ul>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/49cf7ea74f1d26f437088b2b244ba417.jpg"></li>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/dcd5178b4c81cd15d7465af2a33c0d6d.jpg"></li>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/560306a4274d1fc26eb475dd52237387.jpg"></li>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/b46094cb1b7015955b10a42dc949c5d9.jpg"></li>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/9544aaed0500309bfed0ddfc0321f933.jpg"></li>
          <li class="item" data-background-image="https://img.timelessq.com/images/2022/07/26/4ae00b1d55fc55227c12fbe35843514e.jpg"></li>
        </ul>
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">Home</a></span><i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E8%BF%90%E7%BB%B4/" itemprop="item" rel="index" title="In 运维"><span itemprop="name">运维</span></a>
<meta itemprop="position" content="1" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="http://example.com/2024/07/01/GPU%E5%85%A5%E9%97%A8%E6%A6%82%E8%AE%BA/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/avatar.jpg">
    <meta itemprop="name" content="John Doe">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Hexo">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="gpu入门概论"><a class="markdownIt-Anchor" href="#gpu入门概论">#</a> GPU 入门概论</h1>
<p>摘要：本篇文章旨在为后续 LLM 文章做铺垫，通过本篇文章，我们可以理解：</p>
<blockquote>
<p>1、GPU 核心架构及参数</p>
<p>2、2024 主流 GPU 规格及对比</p>
<p>3、NVIDIA 搞的一些奇妙技术</p>
<p>4、云厂商售卖的 GPU 都有啥</p>
<p>5、hands-on lab 自己安装驱动，实现跑开源模型！</p>
<p>PS: 本文中如果没有特值，GPU 均指 NVIDIA 的 GPU，本文不讨论华为昇腾 GPU 或 AMD 的 GPU</p>
</blockquote>
<h2 id="前置芝士"><a class="markdownIt-Anchor" href="#前置芝士">#</a> 前置芝士</h2>
<h3 id="pcie-交换芯片"><a class="markdownIt-Anchor" href="#pcie-交换芯片">#</a> PCIe 交换芯片</h3>
<p>CPU、内存、存储（NVME）、GPU、网卡等支持 PCIe 的设备，都可以连接到 PCIe 总线或专门的 PCIe 交换芯片，实现互联互通。</p>
<p>PCIe 目前有 5 代产品，最新的是  <code>Gen5</code> 。比如下面 H20 和 A800 的对比，H20 使用的是 PCIe Gen5，速度更快。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804232458967.png" alt="image-20240804232458967"></p>
<h3 id="什么是显卡"><a class="markdownIt-Anchor" href="#什么是显卡">#</a> 什么是显卡？</h3>
<p>显卡（Video card，Graphics card）全称显示接口卡，又称显示适配器，是计算机最基本配置、最重要的配件之一。显卡作为电脑主机里的一个重要组成部分，是电脑进行数模信号转换的设备，承担输出显示图形的任务。显卡接在电脑主板上，它将电脑的数字信号转换成模拟信号让显示器显示出来，同时显卡还是有图像处理能力，可协助 CPU 工作，提高整体的运行速度。对于从事专业图形设计的人来说显卡非常重要。民用和军用显卡图形芯片供应商主要包括 AMD (超微半导体) 和 Nvidia (英伟达) 2 家。在科学计算中，显卡被称为显示加速卡。</p>
<h3 id="什么是显存"><a class="markdownIt-Anchor" href="#什么是显存">#</a> 什么是显存？</h3>
<p>也被叫做帧缓存，它的作用是用来存储显卡芯片处理过或者即将提取的渲染数据。如同计算机的内存一样，显存是用来存储要处理的图形信息的部件。</p>
<h3 id="显卡-显卡驱动-cuda之间的关系"><a class="markdownIt-Anchor" href="#显卡-显卡驱动-cuda之间的关系">#</a> 显卡、显卡驱动、CUDA 之间的关系</h3>
<p>显卡：（GPU），主流是 NVIDIA 的 GPU，因为深度学习本身需要大量计算。GPU 的并行计算能力，在过去几年里恰当地满足了深度学习的需求。AMD 的 GPU 基本没有什么支持，可以不用考虑。</p>
<p>驱动：没有显卡驱动，就不能识别 GPU 硬件，不能调用其计算资源。但是，NVIDIA 在 Linux 上的驱动安装特别麻烦。</p>
<p>CUDA：是显卡厂商 NVIDIA 推出的只能用于自家 GPU 的并行计算框架。只有安装这个框架才能够进行复杂的并行计算。主流的深度学习框架也都是基于 CUDA 进行 GPU 并行加速的，几乎无一例外。还有一个叫做 cudnn，是针对深度卷积神经网络的加速库。</p>
<h3 id="显卡驱动与cuda的关系"><a class="markdownIt-Anchor" href="#显卡驱动与cuda的关系">#</a> 显卡驱动与 cuda 的关系</h3>
<p>NVIDIA 的显卡驱动器与 CUDA 并不是一一对应的，CUDA 本质上只是一个工具包而已，所以我可以在同一个设备上安装很多个不同版本的 CUDA 工具包，比如可以同时安装 CUDA 9.0、CUDA 9.2、CUDA 10.0 三个版本。一般情况下，我只需要安装最新版本的显卡驱动，然后根据自己的选择选择不同 CUDA 工具包就可以了，但是由于使用离线的 CUDA 总是会捆绑 CUDA 和驱动程序，所以在使用多个 CUDA 的时候就不要选择离线安装的 CUDA 了，否则每次都会安装不同的显卡驱动，这不太好，我们直接安装一个最新版的显卡驱动，然后在线安装不同版本的 CUDA 即可。</p>
<p>为什么 GPU 特别擅长处理图像数据呢？</p>
<p>这是因为图像上的每一个像素点都有被处理的需要，而且每个像素点处理的过程和方式都十分相似，GPU 就是用很多简单的计算单元去完成大量的计算任务，类似于纯粹的人海战术。GPU 不仅可以在图像处理领域大显身手，它还被用来科学计算、密码破解、数值分析，海量数据处理（排序，Map-Reduce 等），金融分析等需要大规模并行计算的领域。</p>
<h3 id="带宽单位"><a class="markdownIt-Anchor" href="#带宽单位">#</a> 带宽单位</h3>
<p>大规模 GPU 训练的性能与数据传输速度有直接关系。这里面涉及到很多链路，比如 PCIe 带宽、内存带宽、NVLink 带宽、HBM 带宽、网络带宽等等。</p>
<ul>
<li>网络习惯用  <code>bits/second (b/s)</code>  表示之外，并且一般说的都是单向（TX/RX）；</li>
<li>其他模块带宽基本用  <code>byte/sedond (B/s)</code>  或  <code>transactions/second (T/s)</code>  表示，并且一般都是双向总带宽。</li>
</ul>
<h2 id="gpu核心架构及参数"><a class="markdownIt-Anchor" href="#gpu核心架构及参数">#</a> GPU 核心架构及参数</h2>
<p>NVIDIA 数据中心级 GPU，目前在售产品有 B100、H200、L40S、A100、A800、H100、H800、V100。参考：</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9yZXNvdXJjZXMubnZpZGlhLmNvbS9sL2VuLXVzLWdwdT9uY2lkPW5vLW5jaWQ=">https://resources.nvidia.com/l/en-us-gpu?ncid=no-ncid</span></p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804230956526.png" alt="image-20240804230956526"></p>
<p>在了解 V100、A100、H100 这几款 GPU 的区别之前，我们先来简单了解下 NVIDIA GPU 的核心参数，这样能够更好地帮助我们了解这些 GPU 的差别和各自的优势。</p>
<h3 id="算力指标"><a class="markdownIt-Anchor" href="#算力指标">#</a> 算力指标</h3>
<p><strong>FLOPS（每秒浮点运算次数）：</strong></p>
<p>GPU 的算力指标主要指的是每秒可以执行的浮点运算次数，通常用 FLOPS（Floating Point Operations Per Second）来表示。 这是衡量 GPU 性能的关键参数之一。除了基本的 FLOPS，还有其他单位如 GFLOPS、TFLOPS 等，用于表示不同规模的浮点运算能力：</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8xODkzNjY1">https://cloud.tencent.com/developer/article/1893665</span></p>
<p>1 个 MFLOPS (megaFLOPS) 等于每秒一百万 (=10^6) 次的浮点运算量</p>
<p>1 个 GFLOPS (gigaFLOPS) 等于每秒十亿 (=10^9) 次的浮点运算草量:</p>
<p>1 个 TFLOPS (teraFLOPS) 等于每秒一万亿 (=10^12) 次的浮点运算量</p>
<p><strong>CUDA 核心和流处理器</strong>：</p>
<ul>
<li><strong>CUDA 核心</strong>：NVIDIA GPU 中的基本处理单元，用于执行计算任务。</li>
<li><strong>流处理器</strong>：在 AMD GPU 中相似的基本处理单元。</li>
</ul>
<p><strong>带宽和内存</strong>：</p>
<ul>
<li><strong>带宽</strong>：GPU 的内存带宽影响其数据传输速率，直接影响计算性能。</li>
<li><strong>显存容量</strong>：较大的显存容量允许处理更大的数据集，特别是在高分辨率图形和大型数据集的计算中。</li>
</ul>
<h3 id="核心类型"><a class="markdownIt-Anchor" href="#核心类型">#</a> 核心类型</h3>
<p>在 NVIDIA 的通用 GPU 架构中，存在三种主要的核心类型：CUDA Core、Tensor Core 以及 RT Core</p>
<h4 id="cuda-core"><a class="markdownIt-Anchor" href="#cuda-core">#</a> CUDA Core</h4>
<p>CUDA Core：CUDA Core 是 NVIDIA GPU 上的计算核心单元，用于执行通用的并行计算任务，是最常看到的核心类型。NVIDIA 通常用最小的运算单元表示自己的运算能力，CUDA Core 指的是一个执行基础运算的处理元件，我们所说的 CUDA Core 数量，通常对应的是 FP32 计算单元的数量。</p>
<h4 id="tensor-core"><a class="markdownIt-Anchor" href="#tensor-core">#</a> Tensor Core</h4>
<p>Tensor Core：Tensor Core 是 NVIDIA Volta 架构及其后续架构（如 Ampere 架构）中引入的一种特殊计算单元。它们专门用于深度学习任务中的张量计算，如 [矩阵乘法] 和卷积运算。Tensor Core 核心特别大，通常与深度学习框架（如 TensorFlow 和 PyTorch）相结合使用，它可以把整个矩阵都载入寄存器中批量运算，实现十几倍的效率提升。</p>
<h4 id="rt-core"><a class="markdownIt-Anchor" href="#rt-core">#</a> RT Core</h4>
<p>RT Core：RT Core 是 NVIDIA 的专用硬件单元，主要用于加速光线追踪计算。正常数据中心级的 GPU 核心是没有 RT Core 的，主要是消费级显卡才为光线追踪运算添加了 RTCores。RT Core 主要用于游戏开发、电影制作和虚拟现实等需要实时渲染的领域。</p>
<h3 id="nvidia-gpu-架构的演进"><a class="markdownIt-Anchor" href="#nvidia-gpu-架构的演进">#</a> NVIDIA GPU 架构的演进</h3>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231008532.png" alt="image-20240804231008532"></p>
<blockquote>
<p>从上图中就可以看出，V100 是前一代的算力大哥 ，而 H100 则是新一代的大哥，这些架构区别：</p>
<p>Volta 架构：Volta 架构是 NVIDIA GPU 的第六代架构，发布于 2017 年。Volta 架构专注于深度学习和人工智能应用，并引入了 Tensor Core。</p>
<p>Turing 架构：Turing 架构是 NVIDIA GPU 的第七代架构，发布于 2018 年。Turing 架构引入了实时光线追踪（RTX）和深度学习超采样（DLSS）等重要功能。</p>
<p>Ampere 架构：Ampere 架构是 NVIDIA GPU 的第八代架构，2020 年发布。Ampere 架构在计算能力、能效和深度学习性能方面都有重大提升。Ampere 架构的 GPU 采用了多个 [流多处理器]（SM）和更大的总线宽度，提供了更多的 CUDA Core 和更高的频率。它还引入了第三代 Tensor Core，提供更强大的深度学习计算性能。Ampere 架构的 GPU 还具有更高的内存容量和带宽，适用于大规模的数据处理和机器学习任务。</p>
<p>Hopper 架构：Hopper 架构是 NVIDIA GPU 的第九代架构，2022 年发布。相较于 Ampere，Hopper 架构支持第四代 Tensor Core，且采用新型流式处理器，每个 SM 能力更强。Hopper 架构在计算能力、深度学习加速和图形功能方面带来新的创新和改进。</p>
</blockquote>
<p>NVIDIA 显卡从 Tesla 架构开始 (Tesla 架构是 Fermi 前一个架构)，所有 GPU 都带有有 CUDA Core，但 Tensor Core 和 RT Core 却并非都具有。</p>
<p>在 Fermi 架构之前，GPU 的处理核心一直被叫做 Processor core (SPs)，随着 GPU 中处理核心的增加，直到 2010 年 NVIDIA 的 Fermi 架构它被换了一个新的名字 CUDA Core。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231020721.png" alt="image-20240804231020721"></p>
<p>由于 CUDA core 在显卡里面是并行运算，也就是说大家分工计算。从逻辑上说，那么 CUDA core 越多，算力也就相应的会越强。所以说从 Fermi 架构开始，2012 年的 Kepler 架构和 2014 年的 Maxwell 架构，都在这个基础上疯狂加倍增加 Cuda Core。</p>
<p>到了 2016 年的 Pascal 架构，NVIDIA GPU 也开始往深度学习方向进行演进，NVLink 也是这个时候开始引入的。</p>
<p>到了 2017 年引入的 Volta 架构，引入了张量核 Tensor Core 模块，用于执行融合乘法加法，标志着第一代 Tensor Core 核心的诞生。</p>
<p>自从 Volta 架构搭载了首代 Tensor Core 以来，NVIDIA 在每一次的架构升级中都不断对 Tensor Core 进行优化和更新，每一轮的更新都带来了新的变化和提升。</p>
<h2 id="nvidia的小玩意"><a class="markdownIt-Anchor" href="#nvidia的小玩意">#</a> NVIDIA 的小玩意</h2>
<h3 id="nvlink"><a class="markdownIt-Anchor" href="#nvlink">#</a> NVLink</h3>
<p>在 GPU Direct P2P 技术中，多个 GPU 通过 PCle 直接与 CPU 相连，而 PCle 的双向带宽存在上限，当训练数据一直增长</p>
<p>时，PCle 的带宽显然满足不了训练需求。为进一步提升多 0GPU 之间的通信性能，充分发挥 GPU 的算力，NVIDIA 于</p>
<p>2016 年发布了全新架构的 NVLink。</p>
<p>NVLink 是服务器内部 GPU 之间点到点通讯的一种协议，主要目的的是为 GPU 互联提供一个高速点对点的网络。对比传</p>
<p>统网络不会有例如端到端报文重传、自适应路由、报文重组等开开销。极度简化的 NVLink 接口可以为 CUDA 提供从会话</p>
<p>层、表示层到应用层的加速，从而进一步减少因为通讯带来的网络开销</p>
<p>简单总结：同主机内不同 GPU 之间的一种高速互联方式，</p>
<ol>
<li>是一种短距离通信链路，保证包的成功传输，更高性能，替代 PCIe，</li>
<li>支持多 lane，link 带宽随 lane 数量线性增长，</li>
<li>同一台 node 内的 GPU 通过 NVLink 以 full-mesh 方式（类似 spine-leaf）互联，</li>
<li>NVIDIA 专利技术。</li>
</ol>
<p>NVLink 演进：</p>
<p>主要区别是单条 NVLink 链路的 lane 数量、每个 lane 的带宽（图中给的都是双向带宽）等：</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231034286.png" alt="image-20240804231034286"></p>
<p>例如，</p>
<ul>
<li>A100 是  <code>2 lanes/NVSwitch * 6 NVSwitch * 50GB/s/lane= 600GB/s</code>  双向带宽（单向 300GB/s）。注意：这是一个 GPU 到所有 NVSwitch 的总带宽；</li>
<li>A800 被阉割了 4 条 lane，所以是  <code>8 lane * 50GB/s/lane = 400GB/s</code>  双向带宽（单向 200GB/s）。</li>
</ul>
<h3 id="nvswitch"><a class="markdownIt-Anchor" href="#nvswitch">#</a> NVSwitch</h3>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231047361.png" alt="image-20240804231047361"></p>
<p>NVSwitch 是 NVIDIA 的一款交换芯片，封装在 GPU module 上，并不是主机外的独立交换机。</p>
<p>下面是真机图，浪潮的机器，图中 8 个盒子就是 8 片 A100，右边的 6 块超厚散热片下面就是 NVSwitch 芯片：</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231101650.png" alt="image-20240804231101650"></p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231112142.png" alt="image-20240804231112142"></p>
<p>H100 的四个 nvswitch 的芯片</p>
<h3 id="nvlink-switch"><a class="markdownIt-Anchor" href="#nvlink-switch">#</a> NVLink Switch</h3>
<p><code>NVSwitch</code>  听名字像是交换机，但实际上是 GPU module 上的交换芯片，用来连接同一台主机内的 GPU。</p>
<p>2022 年，NVIDIA 把这块芯片拿出来真的做成了交换机，叫  <code>NVLink Switch</code>  [3]， 用来跨主机连接 GPU 设备。</p>
<h3 id="hbm-high-bandwidth-memory"><a class="markdownIt-Anchor" href="#hbm-high-bandwidth-memory">#</a> HBM (High Bandwidth Memory)</h3>
<p>传统上，GPU 显存和普通内存（DDR）一样插在主板上，通过 PCIe 连接到处理器（CPU、GPU）， 因此速度瓶颈在 PCIe，Gen4 是 64GB/s，Gen5 是 128GB/s。</p>
<p>因此，一些 GPU 厂商（不是只有 NVIDIA 一家这么做）将将多个 DDR 芯片堆叠之后与 GPU 芯片封装到一起 （后文讲到 H100 时有图），这样每片 GPU 和它自己的显存交互时，就不用再去 PCIe 交换芯片绕一圈，速度最高可以提升一个量级。 这种 “高带宽内存”（High Bandwidth Memory）缩写就是 HBM。</p>
<blockquote>
<p>现在 CPU 也有用 HBM 的了，比如 <span class="exturl" data-url="aHR0cHM6Ly93d3cuaW50ZWwuY29tL2NvbnRlbnQvd3d3L3VzL2VuL3Byb2R1Y3RzL2RldGFpbHMvcHJvY2Vzc29ycy94ZW9uL21heC1zZXJpZXMuaHRtbA==">Intel Xeon CPU Max Series</span> 就自带了 64GB HBM2e。</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>Bandwidth</th>
<th>Year</th>
<th>GPU</th>
</tr>
</thead>
<tbody>
<tr>
<td>HBM</td>
<td>128GB/s/package</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HBM2</td>
<td>256GB/s/package</td>
<td>2016</td>
<td>V100</td>
</tr>
<tr>
<td>HBM2e</td>
<td>~450GB/s</td>
<td>2018</td>
<td>A100, ~2TB/s; 华为 Ascend 910B</td>
</tr>
<tr>
<td>HBM3</td>
<td>600GB/s/site</td>
<td>2020</td>
<td>H100, 3.35TB/s</td>
</tr>
<tr>
<td>HBM3e</td>
<td>~1TB/s</td>
<td>2023</td>
<td>H200, <span class="exturl" data-url="aHR0cHM6Ly93d3cubnZpZGlhLmNvbS9lbi11cy9kYXRhLWNlbnRlci9oMjAwLw==">4.8TB/s</span></td>
</tr>
</tbody>
</table>
<h3 id="rdma"><a class="markdownIt-Anchor" href="#rdma">#</a> RDMA</h3>
<p>RDMA，即  <code>Remote Direct Memory Access</code> ，是一种绕过<strong>远程</strong>主机  <code>OS kernel</code>  访问其内存中数据的技术，概念源自于  <code>DMA</code>  技术。在 DMA 技术中，外部设备（PCIe 设备）能够绕过 CPU 直接访问  <code>host memory</code> ；而 RDMA 则是指外部设备能够绕过 CPU，不仅可以访问本地主机的内存，还能够访问另一台主机上的用户态内存。由于不经过操作系统，不仅节省了大量 CPU 资源，同样也<strong>提高了系统吞吐量</strong>、<strong>降低了系统的网络通信延迟</strong>，在高性能计算和深度学习训练中得到了广泛的应用。</p>
<p>随着软件定义数据中心、CPU 核心、PCIe、闪存等技术的发展，数据在计算和存储方面的瓶颈并没有太明显，而网络随着数据中心的发展逐渐成为了瓶颈，它直接影响到数据中心最大吞吐量和最小的延迟。</p>
<p>**TCP/IP 协议中的传输方式是以操作系统为中心来完成的。** 如下图所示，将一个应用服务器中的数据传输到另一个服务器中，数据在服务器的 Buffer 内多次拷贝，OS 在将消息发送给网络适配器并通过网络传输之前复制消息。同时在接收端，OS 再次处理数据。</p>
<p><strong>这些操作既增加了数据传输时延，又消耗了大量的 CPU 资源，无法很好得满足高性能计算的需求。</strong></p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231138806.png" alt="image-20240804231138806"></p>
<p>传统以太网卡通信过程:</p>
<p>1、首先，CPU 将数据从用户空间复制到内核空间，内核空间的网络协议栈给数据添加各协议的头部和校验信息；</p>
<p>2、发送端网卡通过 DMA 从主机内存中复制数据到硬件内部缓存中；</p>
<p>3、发送端网卡通过物理链路途径交换机将数据发送给对端的网卡；</p>
<p>4、接收端网卡接收到数据放到缓存中，并通过 DMA 拷贝到系统内存中；</p>
<p>5、CPU 对数据包进行逐层解析和校验，最后将数据复制到用户空间；</p>
<p>整个通信过程中，一共发生了 5 次数据拷贝，其中有 3 次是不可避免的 (按照现有计算机体系架构来说), 其中上图中</p>
<p>234 是不可避免的，而 1 和 5 都是属于系统内存内部中的拷贝。</p>
<p>使用 RDMA 后，RDMA 将服务器应用数据直接由内存传输到智能网卡（固化 RDMA 协议），由智能网卡硬件完成 RDMA 传输报文封装，解放了操作系统和 CPU。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231148241.png" alt="image-20240804231148241"></p>
<blockquote>
<ul>
<li>零拷贝 (Zero-copy) - 应用程序能够直接执行数据传输，在不涉及到网络软件栈的情况下。数据能够被直接发送到缓冲区或者能够直接从缓冲区里接收，而不需要被复制到网络层。</li>
<li>内核旁路 (Kernel bypass) - 应用程序可以直接在用户态执行数据传输，不需要在内核态与用户态之间做上下文切换。</li>
<li>不需要 CPU 干预 (No CPU involvement) - 应用程序可以访问远程主机内存而不消耗远程主机中的任何 CPU。远程主机内存能够被读取而不需要远程主机上的进程（或 CPU) 参与。远程主机的 CPU 的缓存 (cache) 不会被访问的内存内容所填充。</li>
</ul>
</blockquote>
<p>响应 RDMA 对硬件有更高的要求</p>
<p>1、发送端网卡通过 DMA 从用户空间内存复制数据到硬件内部缓存中，并给数据添加各协议层头部和校验信息；</p>
<p>2、发送端网卡通过物理链路途径交换机将数据发送给对端的网卡；</p>
<p>3、接收端网卡收到数据后，先把各协议头部和校验信息剥离，然后将硬件缓存中的数据通过 DMA 拷贝到用户空间。</p>
<p>目前 RDMA 有三种不同的技术实现方式：</p>
<p>InfiniBand（IB）：IB 是一种高性能互连技术，它提供了原生的 RDMA 支持。IB 网络使用专用的 IB 适配器和交换机，通过 RDMA 操作实现节点之间的高速直接内存访问和数据传输。</p>
<p>RoCE（RDMA over Converged Ethernet）：RoCE 是在以太网上实现 RDMA 的技术。它使用标准的以太网作为底层传输介质，并通过使用 RoCE 适配器和适当的协议栈来实现 RDMA 功能。</p>
<p>iWARP：iWARP 是基于 TCP/IP 协议栈的 RDMA 实现。它使用普通的以太网适配器和标准的网络交换机，并通过在 TCP/IP 协议栈中实现 RDMA 功能来提供高性能的远程内存访问和数据传输。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhbmRhb3l1L2FydGljbGUvZGV0YWlscy8xMjQxNjIzMjA=">RDMA 架构与实践 (技术详解 (一):RDMA 概述)-CSDN 博客</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TWpNNU1Ea3pNekF4TUE9PSZhbXA7bWlkPTI0NzE4MTQ4NjMmYW1wO2lkeD0xJmFtcDtzbj0yY2RlYjhkYmJjNTBjZTdmZDQwN2M1MjJkOTUxZTJkMCZhbXA7Y2hrc209YjAxZDBmYjI4NzZhODZhNGM4MmVhNmI0ZWMxZjFiZGMxNDBhMzU3NTlmYTA4YzFmMjdiMjJmYzUyNjNjZjdlZDMyMjFmYjU2Y2UzMyZhbXA7c2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">RDMA</span></p>
<h4 id="单机多卡gpu通信技术"><a class="markdownIt-Anchor" href="#单机多卡gpu通信技术">#</a> 单机多卡 GPU 通信技术</h4>
<h5 id="gpudirect"><a class="markdownIt-Anchor" href="#gpudirect">#</a> GPUDirect</h5>
<p>GPUDirect 是 NVIDIA 开发的一项技术，可实现 GPU 与其他设备（例如网络接口卡 (NIC) 和存储设备）之间的直接通信和数据传输，而不涉及 CPU。</p>
<p>使用 GPUDirect，网络适配器和存储驱动器可以直接读写 GPU 内存，减少不必要的内存消耗，减少 CPU 开销并降低延迟，从而显著提高性能。</p>
<p>GPUDirect 技术已经逐渐完善，形成了包括 GPUDirect Storage、GPUDirect RDMA、GPUDirect P2P 和 GPUDirect Video 四组重要技术的组合。</p>
<p><em>1）GPUDirect Storage</em></p>
<p>对 AI 和 HPC 应用而言，随着数据规模的不断扩大，数据加载时间对系统性能影响越发显著。随着 GPU 计算速度的快速提升，系统 I/O（数据从存储读取到 GPU 显存）已经成为系统瓶颈。</p>
<p>GPUDirect Storage 提供本地存储（NVMe）/ 远程存储（NVMe over Fabric）与 GPU 显存的直接通路，它可以减少不必要的系统内存拷贝（通过 bounce buffer）。它可应用网卡 NIC 和存储系统附近的 DMA 引擎，直接向 GPU 显存写入 / 读取数据。</p>
<p><em>2）GPUDirect RDMA</em></p>
<p>RDMA (Remote direct memory access) 技术可使外围 PCIe 设备直接访问 GPU 显存。GPUDirect RDMA 被设计用来支持 GPU 间快速跨机通信。它能减轻 CPU 负载，同时也能减少不必要的通过系统内存进行的数据拷贝。</p>
<p><em>3）GPUDirect for Video</em></p>
<p>GPUDirect for Video 提供一个服务于 frame-based 的通过优化的流水线功能。设备包括：frame grabbers、video switchers、HD-SDI capture、CameraLink device，它可以把视频帧高效地向 GPU 显内中写入 / 读出。</p>
<p><em>4）GPUDirect P2P</em></p>
<p>GPUDirect P2P 支持 GPU 之间通过 memory fabric（PCIe 或 NVLink）直接进行数据拷贝。</p>
<h4 id="多机之间gpu卡通信技术"><a class="markdownIt-Anchor" href="#多机之间gpu卡通信技术">#</a> 多机之间 GPU 卡通信技术</h4>
<p>GPUDirect RDMA</p>
<p>GPUDirect RDMA 结合了 GPU 加速计算和 RDMA（Remote Direct Memory Access）技术，实现了在 GPU 和 RDMA 网络设备之间直接进行数据传输和通信的能力。它允许 GPU 直接访问 RDMA 网络设备中的数据，无需通过主机内存或 CPU 的中介。</p>
<p>GPUDirect RDMA 通过绕过主机内存和 CPU，直接在 GPU 和 RDMA 网络设备之间进行数据传输，显著降低传输延迟，加快数据交换速度，并可以减轻 CPU 负载，释放 CPU 的计算能力。另外，GPUDirect RDMA 技术允许 GPU 直接访问 RDMA 网络设备中的数据，避免了数据在主机内存中的复制，提高了数据传输的带宽利用率</p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODM5Mjg0MTc=">一文读懂 GPU 通信互联技术：到底什么是 GPUDirect、NVLink、RDMA？</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uY24vcG9zdC83Mjc0OTEyOTk5NTYzMTQ5MzY3">聊透 GPU 通信技术 ——GPU Direct、NVLink、RDMA - 掘金</span></p>
<h2 id="nvidia-gpu详解"><a class="markdownIt-Anchor" href="#nvidia-gpu详解">#</a> NVIDIA GPU 详解</h2>
<h3 id="a100a800"><a class="markdownIt-Anchor" href="#a100a800">#</a> A100/A800</h3>
<p>主机内拓扑： <code>2-2-4-6-8-8</code></p>
<blockquote>
<ul>
<li>2 片 CPU（及两边的内存，NUMA）</li>
<li>2 张存储网卡（访问分布式存储，带内管理等）</li>
<li>4 个 PCIe Gen4 Switch 芯片</li>
<li>6 个 NVSwitch 芯片</li>
<li>8 个 GPU</li>
<li>8 个 GPU 专属网卡</li>
</ul>
</blockquote>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231204105.png" alt="image-20240804231204105"></p>
<p>将所有部件画出来后，会更清晰些</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231237739.png" alt="image-20240804231237739"></p>
<h4 id="存储网卡"><a class="markdownIt-Anchor" href="#存储网卡">#</a> 存储网卡</h4>
<p>通过 PCIe 直连 CPU。用途：</p>
<ol>
<li>从分布式存储读写数据，例如读训练数据、写 checkpoint 等；</li>
</ol>
<blockquote>
<p>checkpoint&quot;并不是指一个具体的文件或文件夹名，而是指在训练过程中保存的模型状态。具体来说，&quot;Saving checkpoint at 8 epochs&quot; 意味着在训练的第 8 个 epoch 结束时，程序自动保存了这个时刻模型的权重和状态。这样做是为了在后续的训练过程中，如果需要中断或重启训练，可以直接从这个 checkpoint 开始，而不必从头开始训练，这样可以大大节省时间和资源</p>
</blockquote>
<ol>
<li>正常的 node 管理，ssh，监控采集等等。</li>
</ol>
<p>官方推荐用 BF3 DPU。但其实只要带宽达标，用什么都行。组网经济点的话用 RoCE，追求最好的性能用 IB。</p>
<h4 id="nvswitch-fabricintra-node-full-mesh"><a class="markdownIt-Anchor" href="#nvswitch-fabricintra-node-full-mesh">#</a> NVSwitch fabric：intra-node full-mesh</h4>
<p>8 个 GPU 通过 6 个 NVSwitch 芯片 full-mesh 连接，这个 full-mesh 也叫  <code>NVSwitch fabric</code> ； full-mesh 里面的每根线的带宽是 n * bw-per-nvlink-lane，</p>
<ul>
<li>A100 用的 NVLink3， <code>50GB/s/lane</code> ，所以 full-mesh 里的每条线就是  <code>12*50GB/s=600GB/s</code> ，注意这个是双向带宽，单向只有 300GB/s。</li>
<li>A800 是阉割版，12 lane 变成 8 lane，所以每条线 8*50GB/s=400GB/s，单向 200GB/s。</li>
</ul>
<h4 id="smi-topo"><a class="markdownIt-Anchor" href="#smi-topo">#</a> smi topo</h4>
<p>下面是一台 8*A800 机器上  <code>nvidia-smi</code>  显示的实际拓</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231250720.png" alt="image-20240804231250720"></p>
<ul>
<li>GPU 之间（左上角区域）：都是  <code>NV8</code> ，表示 8 条 NVLink 连接；</li>
<li>NIC 之间：
<ul>
<li>在同一片 CPU 上： <code>NODE</code> ，表示不需要跨 NUMA，但需要跨 PCIe 交换芯片；</li>
<li>不在同一片 CPU 上： <code>SYS</code> ，表示需要跨 NUMA；</li>
</ul>
</li>
<li>GPU 和 NIC 之间：
<ul>
<li>在同一片 CPU 上，且在同一个 PCIe Switch 芯片下面： <code>PXB</code> ，表示只需要跨 PCIe 交换芯片；</li>
<li>在同一片 CPU 上，且不在同一个 PCIe Switch 芯片下面： <code>NODE</code> ，表示需要跨 PCIe 交换芯片和 PCIe Host Bridge；</li>
<li>不在同一片 CPU 上： <code>SYS</code> ，表示需要跨 NUMA、PCIe 交换芯片，距离最远；</li>
</ul>
</li>
</ul>
<h4 id="gpu-训练集群组网idc-gpu-fabirc"><a class="markdownIt-Anchor" href="#gpu-训练集群组网idc-gpu-fabirc">#</a> GPU 训练集群组网：IDC GPU fabirc</h4>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231303309.png" alt="image-20240804231303309"></p>
<h4 id="计算网络"><a class="markdownIt-Anchor" href="#计算网络">#</a> 计算网络</h4>
<p>GPU 网卡直连到置顶交换机（leaf），leaf 通过 full-mesh 连接到 spine，形成跨主机 GPU 计算网络。</p>
<ul>
<li>这个网络的目的是 GPU 与其他 node 的 GPU 交换数据；</li>
<li>每个 GPU 和自己的网卡之间通过 PCIe 交换芯片连接： <code>GPU &lt;--&gt; PCIe Switch &lt;--&gt; NIC</code> 。</li>
</ul>
<h4 id="存储网络"><a class="markdownIt-Anchor" href="#存储网络">#</a> 存储网络</h4>
<p>直连 CPU 的两张网卡，连接到另一张网络里，主要作用是读写数据，以及 SSH 管理等等。</p>
<h4 id="单机-8-卡-a100-gpu-主机带宽瓶颈分析"><a class="markdownIt-Anchor" href="#单机-8-卡-a100-gpu-主机带宽瓶颈分析">#</a> 单机 8 卡 A100 GPU 主机带宽瓶颈分析</h4>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231313807.png" alt="image-20240804231313807"></p>
<blockquote>
<p>几个关键链路带宽都标在图上了，</p>
<ol>
<li>同主机 GPU 之间：走 NVLink，双向 600GB/s，单向  <code>300GB/s</code> ；</li>
<li>同主机 GPU 和自己的网卡之间：走 PICe Gen4 Switch 芯片，双向 64GB/s，单向  <code>32GB/s</code> ；</li>
<li>跨主机 GPU 之间：需要通过网卡收发数据，这个就看网卡带宽了，目前国内 A100/A800 机型配套的主流带宽是（单向）  <code>100Gbps=12.5GB/s</code> 。 所以跨机通信相比主机内通信性能要下降很多。
<ol>
<li><code>200Gbps==25GB/s</code> ：已经接近 PCIe Gen4 的单向带宽；</li>
<li><code>400Gbps==50GB/s</code> ：已经超过 PCIe Gen4 的单向带宽。</li>
</ol>
</li>
<li>所以在这种机型里用 400Gbps 网卡作用不大，400Gbps 需要 PCIe Gen5 性能才能发挥出来。</li>
</ol>
</blockquote>
<h3 id="h100h800"><a class="markdownIt-Anchor" href="#h100h800">#</a> H100/H800</h3>
<h4 id="h100芯片"><a class="markdownIt-Anchor" href="#h100芯片">#</a> H100 芯片</h4>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231324996.png" alt="image-20240804231324996"></p>
<ul>
<li><code>4nm</code>  工艺；</li>
<li>最下面一排是 18 根 Gen4 NVLink；双向总带宽  <code>18 lanes * 50GB/s/lane = 900GB/s</code> ；</li>
<li>中间蓝色的是 L2 cache；</li>
<li>左右两侧是  <code>HBM</code>  芯片，即显存；</li>
</ul>
<h4 id="主机内硬件拓扑"><a class="markdownIt-Anchor" href="#主机内硬件拓扑">#</a> 主机内硬件拓扑</h4>
<p>跟 A100 8 卡机结构大致类似，区别：</p>
<ol>
<li>NVSwitch 芯片从 6 个减少到了 4 个</li>
</ol>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231336629.png" alt="image-20240804231336629"></p>
<p>与 CPU 的互联从 PCIe Gen4 x16 升级到  <code>PCIe Gen5 x16</code> ，双向带宽  <code>128GB/s</code> ；</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231348068.png" alt="image-20240804231348068"></p>
<h3 id="l40s"><a class="markdownIt-Anchor" href="#l40s">#</a> L40S</h3>
<p>对标 A100</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231403423.png" alt="image-20240804231403423"></p>
<h4 id="架构"><a class="markdownIt-Anchor" href="#架构">#</a> 架构</h4>
<h5 id="2-2-4"><a class="markdownIt-Anchor" href="#2-2-4">#</a> 2-2-4</h5>
<p>相比于 A100 的  <code>2-2-4-6-8-8</code>  架构， 官方推荐的 L40S GPU 主机是 2-2-4 架构，一台机器物理拓扑如下</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231413159.png" alt="image-20240804231413159"></p>
<p>最明显的变化是去掉了 CPU 和 GPU 之间的 PCIe Switch 芯片， 网卡和 GPU 都是直连 CPU 上自带的 PCIe Gen4 x16（64GB/s），</p>
<ul>
<li>2 片 CPU（NUMA）</li>
<li>2 张双口 CX7 网卡（每张网卡  <code>2*200Gbps</code> ）</li>
<li>4 片 L40S GPU</li>
<li>另外，存储网卡只配 1 张（双口），直连在任意一片 CPU 上</li>
</ul>
<h5 id="2-2-8"><a class="markdownIt-Anchor" href="#2-2-8">#</a> 2-2-8</h5>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231426536.png" alt="image-20240804231426536"></p>
<p>跟单机 4 卡相比，单机 8 卡需要引入两片 PCIe Gen5 Switch 芯片：</p>
<ul>
<li>价格不划算；</li>
<li>PCIe switch 只有一家在生产，产能受限，周期很长；</li>
<li>平摊到每片 GPU 的网络带宽减半；</li>
</ul>
<h4 id="v100a100h100a800l40s对比"><a class="markdownIt-Anchor" href="#v100a100h100a800l40s对比">#</a> V100,A100,H100,A800,L40S 对比</h4>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231443727.png" alt="image-20240804231443727"></p>
<h2 id="火山gpu-云服务器概览"><a class="markdownIt-Anchor" href="#火山gpu-云服务器概览">#</a> 火山 GPU 云服务器概览</h2>
<p><strong>以下都是火山云服务器官方文档内容，有实效性～</strong></p>
<p><strong>模型训练场景</strong> V100、A100、A30 等类型的 GPU 显卡适用于 AI 模型训练场景，提供了大显存和高速访问能力，并叠加 NVLink 多卡互连，为多卡并行提供了超强计算能力。</p>
<p><strong>应用推理场景</strong> T4、A10 等类型的 GPU 显卡为 AI 推理提供了高效能比的加速能力，广泛应用于图像识别、语言翻译场景。</p>
<h3 id="实例规格"><a class="markdownIt-Anchor" href="#实例规格">#</a> 实例规格</h3>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231538728.png" alt="image-20240804231538728"></p>
<h4 id="gpu计算"><a class="markdownIt-Anchor" href="#gpu计算">#</a> GPU 计算</h4>
<p>GPU 计算型实例基于多种 NVIDIA Tesla 显卡，在各类推理场景及分子计算场景下提供高性价比。适用于深度学习及 AI 推理训练，如图像处理、语音识别等人工智能算法的训练应用。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231605505.png" alt="image-20240804231605505"></p>
<h4 id="高性能计算"><a class="markdownIt-Anchor" href="#高性能计算">#</a> 高性能计算</h4>
<p>高性能计算 GPU 型规格在原有 GPU 型规格的基础上，加入 RDMA 网络，可大幅提升网络性能，提高大规模集群加速比，适用于高性能计算、人工智能、机器学习等业务场景。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231613901.png" alt="image-20240804231613901"></p>
<h4 id="gpu渲染"><a class="markdownIt-Anchor" href="#gpu渲染">#</a> GPU 渲染</h4>
<p>GPU 渲染型实例安装了 NVIDIA GRID 驱动并配置了 License 服务器，适用于图形图像处理（3D 渲染，视频编码 / 解码），使用该实例，您可以免除手动配置 GPU 图形图像处理基础环境。</p>
<h3 id="nvidia驱动安装"><a class="markdownIt-Anchor" href="#nvidia驱动安装">#</a> NVIDIA 驱动安装</h3>
<h3 id="cudacudnnfabric-manager"><a class="markdownIt-Anchor" href="#cudacudnnfabric-manager">#</a> CUDA，cuDNN，fabric-manager</h3>
<blockquote>
<p>英伟达官方对于 CUDA (Compute Unified Device Architecture) 的定义是：通用的并行计算平台 和 编程模型。这里的 “通用” 主要指的是可以适配 英伟达的各种产品。当然，现在也有其它厂商做显卡，并尝试适配 CUDA。</p>
<p>在我们给电脑接入 GPU 这个外接设备后，首先要做的事情就是安装 显卡驱动。只有安装上驱动后，才能保证程序的运行。在安装上驱动后，我们就可以使用  <code>nvidia-smi</code>  指令查看显卡的运行状况了。还可以通过  <code>nvidia-smi -q</code>  查看显卡的基本信息。</p>
<p>如果你是普通的玩家用户，安装完成 显卡驱动 就可以了。但是，如果你是开发者，那么就需要安装 CUDA Toolkit, 其内部包含了 nvcc 编译器和 Nvidia Nsight 工具集。在 Nvidia Nsight 中，包含有 CUDA 开发的 IDE, 程序性能分析工具等等。</p>
<p>如果你需要训练或者部署 深度学习 相关的模型，还需要安装 cuDNN, 它仅仅是一个库，和 cuBLAS, cuFFT 是同等级别的。英伟达完全可以将 cuDNN 放在 CUDA Toolkit 中，但是他可能为了强迫 深度学习 研究者买他们的专业卡，故意这么做的。不仅如此，下载 cuDNN 需要登陆账号，而下载 CUDA Toolkit 则不需要登陆账号。同时，安装 cuDNN 的过程就是将几个文件复制到 CUDA Toolkit 文件夹下，不需要干什么额外的事情。</p>
<p>需要注意的是，我们通常所说的安装 CUDA, 就是安装 CUDA Toolkit。不过，现在很多东西都简化了。目前，在最新的 PyTorch 安装包中，会自动包含 CUDA 相关的库文件，不需要自己单独安装了。只需要安装 显卡驱动 即可。</p>
</blockquote>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231627958.png" alt="image-20240804231627958"></p>
<p>使用  <code>nvidia-smi</code>  命令可以看到一个 CUDA 的版本号，但这个版本号是 CUDA driver <span class="exturl" data-url="aHR0cDovL2xpYmN1ZGEuc28=">libcuda.so</span> 的版本号，不是 CUDA Toolkit 的版本号。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231637666.png" alt="image-20240804231637666"></p>
<p>如上图 CUDA driver 是向后兼容的，即支持之前的 CUDA Toolkit 版本。</p>
<p><img data-src="https://kbshire-1308981697.cos.ap-shanghai.myqcloud.com/img/image-20240804231647843.png" alt="image-20240804231647843"></p>
<p>如上图，CUDA driver 支持向前的次要版本兼容，即大版本号相同就支持。</p>
<p>安装 fabric manager</p>
<p>如果装配了 NVLink 或者 NVSwitch ，还需要安装 nvidia-fabricmanager，否则无法正常工作。</p>
<p>FM 职责</p>
<ol>
<li>配置 NVSwitch 端口之间的路由。</li>
<li>与 GPU 驱动程序配合初始化 GPU。</li>
<li>监控结构中的 NVLink 和 NVSwitch 错误。</li>
</ol>
<h3 id="nvidia驱动类型"><a class="markdownIt-Anchor" href="#nvidia驱动类型">#</a> NVIDIA 驱动类型</h3>
<p>NVIDIA 驱动程序是用来驱动 NVIDIA GPU 卡的程序，是硬件所对应的软件，用于提升操作系统对其芯片组的兼容性。当前火山引擎提供的 GPU 实例均为计算型，即 GPU 卡直通型，实例必须安装 GPU 驱动来驱动物理 GPU 卡，以获得 GPU 卡的能力。</p>
<p>GPU 实例当前支持安装以下两种 NVIDIA 驱动</p>
<table>
<thead>
<tr>
<th>驱动类型</th>
<th>驱动介绍</th>
<th>收费情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tesla 驱动</td>
<td>用于驱动物理 GPU 卡，即调用 GPU 云服务器上的 GPU 卡获得通用计算能力，适用于深度学习、推理、AI 等场景。 您可以配合 CUDA、cuDNN 库更高效的使用 GPU 卡。</td>
<td>免费</td>
</tr>
<tr>
<td>GRID 驱动</td>
<td>用于获得 GPU 卡的图形加速能力，适用于 OpenGL 等图形计算的场景。</td>
<td>需购买 NVIDIA GRID License</td>
</tr>
</tbody>
</table>
<h3 id="多机多卡nccl-test"><a class="markdownIt-Anchor" href="#多机多卡nccl-test">#</a> 多机多卡 nccl test</h3>
<blockquote>
<ul>
<li>OpenMPI</li>
</ul>
<p>OpenMPI 是一个开源的 Message Passing Interface 实现，是一种高性能消息传递库，能够结合整个高性能计算社区的专业知识、技术和资源，建立现有的最佳 MPI 库。OpenMPI 在系统和软件供应商、应用开发者和计算机科学研究人员中有广泛应用。</p>
<ul>
<li>NCCL</li>
</ul>
<p>NCCL（Nvidia Collective multi-GPU Communication Library，读作 “Nickel”）是一个提供 GPU 间通信基元的库，它具有拓扑感知能力，可以轻松集成到应用程序中。NCCL 做了很多优化，以在 PCIe、Nvlink、InfiniBand 上实现较高的通信速度。NCCL 支持安装在单个节点或多个节点上的大量 GPU 卡上，并可用于单进程或多进程（如 MPI）应用。</p>
<ul>
<li>NCCL Tests</li>
</ul>
<p>NCCL Tests 是一个测试工具集，可以用来评估 NCCL 的运行性能和正确性。</p>
<ul>
<li>OFED</li>
</ul>
<p>MLNX OFED（OpenFabrics Enterprise Distribution）是一组开源软件驱动、核心内核代码、中间件和支持 InfiniBand Fabric 的用户级接口程序，用于监视 InfiniBand 网络的运行情况，包括监视传输带宽和监视 Fabric 内部的拥塞情况。</p>
</blockquote>
<p><span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9kZXZlbG9wZXIvYXJ0aWNsZS8yMzYxNzEw">nccl-test 使用指引</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N4ZjEwNjE3MDA2MjUvYXJ0aWNsZS9kZXRhaWxzLzE0MDAyODE4MQ==">【教程】简介 nccl-test 工具 - CSDN 博客</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzYzMjE5MTc1L2Fuc3dlci8zNDE0Nzg5NzE1">如何理解 Nvidia 英伟达的 Multi-GPU 多卡通信框架 NCCL?</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01yS2luZ2xvdmV5b3UvYXJ0aWNsZS9kZXRhaWxzLzEzODE2NzE4MA==">多机多卡运行 nccl-tests 对比分析</span></p>
<h2 id="hands-on-lab"><a class="markdownIt-Anchor" href="#hands-on-lab">#</a> Hands-on lab</h2>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82OTI5NjU3NTI=">https://zhuanlan.zhihu.com/p/692965752</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9vcGVuYXRvbXdvcmtzaG9wLmNzZG4ubmV0LzY2NDcwMWQ0YjEyYTlkMTY4ZWI2ZTRkMS5odG1s">https://openatomworkshop.csdn.net/664701d4b12a9d168eb6e4d1.html</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnRodXJjaGlhby5hcnQvYmxvZy9ncHUtYWR2YW5jZWQtbm90ZXMtMS16aC8jMTEtcGNpZS0lRTQlQkElQTQlRTYlOEQlQTIlRTglOEElQUYlRTclODklODc=">https://arthurchiao.art/blog/gpu-advanced-notes-1-zh/#11-pcie - 交换芯片</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl81NDEwNjY4Mi9hcnRpY2xlL2RldGFpbHMvMTM3Mzc1Nzc5">https://blog.csdn.net/weixin_54106682/article/details/137375779</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3JlYWQvY3YzMDc1Mzg3MS8=">https://www.bilibili.com/read/cv30753871/</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW94aWFvd2VucWlhbmcvYXJ0aWNsZS9kZXRhaWxzLzEzODI3ODc5NQ==">https://blog.csdn.net/xiaoxiaowenqiang/article/details/138278795</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zOTQzNTI0NzY=">https://zhuanlan.zhihu.com/p/394352476</span></p>
<p>cuda:</p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODY3NzI1NDY=">https://zhuanlan.zhihu.com/p/686772546</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9zY2MudXN0Yy5lZHUuY24vemxzYy91c2VyX2RvYy9odG1sL2xhdGV4Lmh0bWw=">https://scc.ustc.edu.cn/zlsc/user_doc/html/latex.html</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82ODAyNjIwMTY=">https://zhuanlan.zhihu.com/p/680262016</span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lncTEzNTcyNTQ5ODc0L2FydGljbGUvZGV0YWlscy8xMzg0Njk0NDU=">https://blog.csdn.net/ygq13572549874/article/details/138469445</span></p>

      <div class="tags">
          <a href="/tags/%E8%BF%90%E7%BB%B4/" rel="tag"><i class="ic i-tag"></i> 运维</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2024-08-04 23:30:55" itemprop="dateModified" datetime="2024-08-04T23:30:55+08:00">2024-08-04</time>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> Donate</button>
  <p>Give me a cup of [coffee]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechatpay.png" alt="John Doe WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div>
        <img data-src="/images/alipay.png" alt="John Doe Alipay">
        <p>Alipay</p>
      </div>
      
      <div>
        <img data-src="/images/paypal.png" alt="John Doe PayPal">
        <p>PayPal</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>John Doe <i class="ic i-at"><em>@</em></i>Hexo
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="http://example.com/2024/07/01/GPU%E5%85%A5%E9%97%A8%E6%A6%82%E8%AE%BA/" title="GPU入门概论">http://example.com/2024/07/01/GPU入门概论/</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/06/01/openstack/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;img.timelessq.com&#x2F;images&#x2F;2022&#x2F;07&#x2F;26&#x2F;7a9a95e33c226d979abfd43d471f610d.jpg" title="OpenStack+openvswitch">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> 运维</span>
  <h3>OpenStack+openvswitch</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/10/01/clickhouse/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;img.timelessq.com&#x2F;images&#x2F;2022&#x2F;07&#x2F;26&#x2F;3c4316b68ee81cc6a059ffc346752e5b.jpg" title="Clickhouse">
  <span class="type">Next Post</span>
  <span class="category"><i class="ic i-flag"></i> 大数据</span>
  <h3>Clickhouse</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#gpu%E5%85%A5%E9%97%A8%E6%A6%82%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text"> GPU 入门概论</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%BD%AE%E8%8A%9D%E5%A3%AB"><span class="toc-number">1.1.</span> <span class="toc-text"> 前置芝士</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#pcie-%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87"><span class="toc-number">1.1.1.</span> <span class="toc-text"> PCIe 交换芯片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%98%BE%E5%8D%A1"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 什么是显卡？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%98%BE%E5%AD%98"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 什么是显存？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E5%8D%A1-%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8-cuda%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.1.4.</span> <span class="toc-text"> 显卡、显卡驱动、CUDA 之间的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E4%B8%8Ecuda%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.1.5.</span> <span class="toc-text"> 显卡驱动与 cuda 的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6%E5%AE%BD%E5%8D%95%E4%BD%8D"><span class="toc-number">1.1.6.</span> <span class="toc-text"> 带宽单位</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gpu%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%8F%82%E6%95%B0"><span class="toc-number">1.2.</span> <span class="toc-text"> GPU 核心架构及参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%8A%9B%E6%8C%87%E6%A0%87"><span class="toc-number">1.2.1.</span> <span class="toc-text"> 算力指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.2.</span> <span class="toc-text"> 核心类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cuda-core"><span class="toc-number">1.2.2.1.</span> <span class="toc-text"> CUDA Core</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tensor-core"><span class="toc-number">1.2.2.2.</span> <span class="toc-text"> Tensor Core</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rt-core"><span class="toc-number">1.2.2.3.</span> <span class="toc-text"> RT Core</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvidia-gpu-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B"><span class="toc-number">1.2.3.</span> <span class="toc-text"> NVIDIA GPU 架构的演进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nvidia%E7%9A%84%E5%B0%8F%E7%8E%A9%E6%84%8F"><span class="toc-number">1.3.</span> <span class="toc-text"> NVIDIA 的小玩意</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#nvlink"><span class="toc-number">1.3.1.</span> <span class="toc-text"> NVLink</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvswitch"><span class="toc-number">1.3.2.</span> <span class="toc-text"> NVSwitch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvlink-switch"><span class="toc-number">1.3.3.</span> <span class="toc-text"> NVLink Switch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hbm-high-bandwidth-memory"><span class="toc-number">1.3.4.</span> <span class="toc-text"> HBM (High Bandwidth Memory)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rdma"><span class="toc-number">1.3.5.</span> <span class="toc-text"> RDMA</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1gpu%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF"><span class="toc-number">1.3.5.1.</span> <span class="toc-text"> 单机多卡 GPU 通信技术</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#gpudirect"><span class="toc-number">1.3.5.1.1.</span> <span class="toc-text"> GPUDirect</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%9C%BA%E4%B9%8B%E9%97%B4gpu%E5%8D%A1%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF"><span class="toc-number">1.3.5.2.</span> <span class="toc-text"> 多机之间 GPU 卡通信技术</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nvidia-gpu%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.4.</span> <span class="toc-text"> NVIDIA GPU 详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#a100a800"><span class="toc-number">1.4.1.</span> <span class="toc-text"> A100&#x2F;A800</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E7%BD%91%E5%8D%A1"><span class="toc-number">1.4.1.1.</span> <span class="toc-text"> 存储网卡</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nvswitch-fabricintra-node-full-mesh"><span class="toc-number">1.4.1.2.</span> <span class="toc-text"> NVSwitch fabric：intra-node full-mesh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#smi-topo"><span class="toc-number">1.4.1.3.</span> <span class="toc-text"> smi topo</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gpu-%E8%AE%AD%E7%BB%83%E9%9B%86%E7%BE%A4%E7%BB%84%E7%BD%91idc-gpu-fabirc"><span class="toc-number">1.4.1.4.</span> <span class="toc-text"> GPU 训练集群组网：IDC GPU fabirc</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.1.5.</span> <span class="toc-text"> 计算网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.1.6.</span> <span class="toc-text"> 存储网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E6%9C%BA-8-%E5%8D%A1-a100-gpu-%E4%B8%BB%E6%9C%BA%E5%B8%A6%E5%AE%BD%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90"><span class="toc-number">1.4.1.7.</span> <span class="toc-text"> 单机 8 卡 A100 GPU 主机带宽瓶颈分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#h100h800"><span class="toc-number">1.4.2.</span> <span class="toc-text"> H100&#x2F;H800</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#h100%E8%8A%AF%E7%89%87"><span class="toc-number">1.4.2.1.</span> <span class="toc-text"> H100 芯片</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%9C%BA%E5%86%85%E7%A1%AC%E4%BB%B6%E6%8B%93%E6%89%91"><span class="toc-number">1.4.2.2.</span> <span class="toc-text"> 主机内硬件拓扑</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#l40s"><span class="toc-number">1.4.3.</span> <span class="toc-text"> L40S</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">1.4.3.1.</span> <span class="toc-text"> 架构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-4"><span class="toc-number">1.4.3.1.1.</span> <span class="toc-text"> 2-2-4</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-8"><span class="toc-number">1.4.3.1.2.</span> <span class="toc-text"> 2-2-8</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#v100a100h100a800l40s%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.3.2.</span> <span class="toc-text"> V100,A100,H100,A800,L40S 对比</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%81%AB%E5%B1%B1gpu-%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A6%82%E8%A7%88"><span class="toc-number">1.5.</span> <span class="toc-text"> 火山 GPU 云服务器概览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%E8%A7%84%E6%A0%BC"><span class="toc-number">1.5.1.</span> <span class="toc-text"> 实例规格</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#gpu%E8%AE%A1%E7%AE%97"><span class="toc-number">1.5.1.1.</span> <span class="toc-text"> GPU 计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97"><span class="toc-number">1.5.1.2.</span> <span class="toc-text"> 高性能计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gpu%E6%B8%B2%E6%9F%93"><span class="toc-number">1.5.1.3.</span> <span class="toc-text"> GPU 渲染</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvidia%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85"><span class="toc-number">1.5.2.</span> <span class="toc-text"> NVIDIA 驱动安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudacudnnfabric-manager"><span class="toc-number">1.5.3.</span> <span class="toc-text"> CUDA，cuDNN，fabric-manager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nvidia%E9%A9%B1%E5%8A%A8%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.5.4.</span> <span class="toc-text"> NVIDIA 驱动类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%9C%BA%E5%A4%9A%E5%8D%A1nccl-test"><span class="toc-number">1.5.5.</span> <span class="toc-text"> 多机多卡 nccl test</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hands-on-lab"><span class="toc-number">1.6.</span> <span class="toc-text"> Hands-on lab</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li><a href="/2022/11/27/CDN/" rel="bookmark" title="CDN&DNS">CDN&DNS</a></li><li><a href="/2023/04/03/iptables2/" rel="bookmark" title="iptables">iptables</a></li><li><a href="/2023/04/05/Docker/" rel="bookmark" title="docker">docker</a></li><li><a href="/2023/04/15/Nginx_new/" rel="bookmark" title="Nginx">Nginx</a></li><li><a href="/2023/05/20/Kubernetes/" rel="bookmark" title="Kubernetes">Kubernetes</a></li><li><a href="/2023/05/30/jenkins/" rel="bookmark" title="Jenkins">Jenkins</a></li><li><a href="/2023/06/02/k8s%E9%AB%98%E7%BA%A7/" rel="bookmark" title="k8s高级">k8s高级</a></li><li><a href="/2024/01/01/istio/" rel="bookmark" title="istio">istio</a></li><li><a href="/2024/01/10/%E9%9B%86%E7%BE%A4%E4%B8%8E%E5%AD%98%E5%82%A8/" rel="bookmark" title="集群与存储">集群与存储</a></li><li><a href="/2024/01/25/%E8%99%9A%E6%8B%9F%E5%8C%96/" rel="bookmark" title="虚拟化">虚拟化</a></li><li><a href="/2024/02/01/%E7%9B%91%E6%8E%A7/" rel="bookmark" title="监控">监控</a></li><li><a href="/2024/02/15/Elastic%20Stack/" rel="bookmark" title="Elastic stack">Elastic stack</a></li><li><a href="/2024/06/01/openstack/" rel="bookmark" title="OpenStack+openvswitch">OpenStack+openvswitch</a></li><li class="active"><a href="/2024/07/01/GPU%E5%85%A5%E9%97%A8%E6%A6%82%E8%AE%BA/" rel="bookmark" title="GPU入门概论">GPU入门概论</a></li><li><a href="/2024/12/01/redis/" rel="bookmark" title="Redis">Redis</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="John Doe"
      data-src="/images/avatar.jpg">
  <p class="name" itemprop="name">John Doe</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">62</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">8</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">8</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>Home</a>
  </li>


</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/06/01/openstack/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/10/01/clickhouse/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E7%BD%91%E7%BB%9C/" title="In 网络">网络</a>
</div>

    <span><a href="/2023/01/20/VXLAN/" title="VXLAN">VXLAN</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E8%BF%90%E7%BB%B4/" title="In 运维">运维</a>
</div>

    <span><a href="/2024/02/01/%E7%9B%91%E6%8E%A7/" title="监控">监控</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/web%E5%AE%89%E5%85%A8/" title="In web安全">web安全</a>
</div>

    <span><a href="/2022/05/17/include/" title="file include">file include</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/2023/04/07/TCPIP_new/" title="TCP&#x2F;IP">TCP/IP</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/2023/03/27/http/" title="http">http</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E8%BF%90%E7%BB%B4/" title="In 运维">运维</a>
</div>

    <span><a href="/2023/06/02/k8s%E9%AB%98%E7%BA%A7/" title="k8s高级">k8s高级</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="In 大模型">大模型</a>
</div>

    <span><a href="/2025/05/01/Deep%20learning/" title="Deep learning">Deep learning</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E8%BF%90%E7%BB%B4/" title="In 运维">运维</a>
</div>

    <span><a href="/2023/04/05/Docker/" title="docker">docker</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/web%E5%AE%89%E5%85%A8/" title="In web安全">web安全</a>
</div>

    <span><a href="/2022/11/27/Docker%E9%80%83%E9%80%B8/" title="docker逃逸&amp;capabilities">docker逃逸&capabilities</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="In 大模型">大模型</a>
</div>

    <span><a href="/2025/07/01/RL/" title="Machine learning">Machine learning</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 2010 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">John Doe @ Yume Shoka</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/07/01/GPU入门概论/',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
